Отток клиентов
Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.

Постройте модель с предельно большим значением F1-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно.

Дополнительно измеряйте AUC-ROC, сравнивайте её значение с F1-мерой.

Источник данных: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling

Цель проекта: Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет.
Предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. Построить модель с предельно большим значением F1-меры, нужно довести метрику до 0.59. Проверить F1-меру на тестовой выборке.

Этапы выполнения:

Загрузить и подготовить данные. Пояснить порядок действий.
Исследовать баланс классов, обучить модель без учёта дисбаланса.
Улучшить качество модели, учитывая дисбаланс классов. Обучить разные модели и найти лучшую. 
Провести финальное тестирование.

Изучили три модели без учета дисбаланса классов: модели логистической регресии, дерева решений и случайного леса.
Модели логистической регресии (Полнота: 0.17, Точность: 0.58, F1 score: 0.27, ROC_auc score: 0.75), дерева решений (модель не сильно лучше слуйчайной) не пригодны для использования.
А модель случайного леса (Полнота 0.41 - низкая, то есть доля правильных положительных ответов всего 41%. Точность высокая 81%, а F1 score 0.54) - модель дает мало положительных ответов.
Для борьбы с дисбалансом классов применили в моделях взвешивание классов, увеличение выборки (upsampling) и уменьшение выборки (downsampling).
Модели логистической регресии, дерева решений не показали качественного улучшения.
В ходе борьбы с дисбалансом классов хорошие результаты показала только модель случайного леса при увеличении выборки обучающих данных. Полнота: 0.66, Точность: 0.598, F1 score: 0.63, ROC_auc score: 0.86.
Наилучший порог классификации: Порог = 0.50.
Проверили лучшую модель на тестовой выборке: модель показала значение F1 score: 0.597, предсказания приемлимые.